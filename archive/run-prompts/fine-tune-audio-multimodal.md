 So in one of the most useful multimodal tools for transcription, I find is Gemini by Google has the ability to take in a binary file audio. And then, of course, you can add your own prompts. I can do with that quite a lot of things that I can't do with just using a speech-to-text model like Whisper. I can say, this is a phone call. The two people are A and B, diarize it accordingly. So it really is a very interesting application. And my question is, it would be really cool to have... A fine-tunable model that worked at that level as opposed to just transcription. Is there anything that exists like that in the realm of open source? I'm also curious as well, this seems to me like quite a fundamentally different technology by Gemini Google. With audio as opposed to Whisper with very different capabilities. And yet I haven't really seen that technology by Google, where you can take in audio and provide a written prompt. Style the transcription as such. I haven't really seen that defined with a name. Does it have its own name, transcription with guidance or something of that nature? And are there any models that are actually purely built for this? In other words, taking the raw transcription ability of ASR models and adding a little bit of determinative LLM guidance and baking that into one model that, as opposed to Gemini, is specialized still in audio workloads but has that sort of additional, very useful text processing capability that goes beyond just transcribing the words and actually edits the text that you get from those.