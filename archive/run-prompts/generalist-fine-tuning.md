So I know that popular reasons for fine tuning are very domain-specific vocabulary, as well as underrepresented languages. My personal reasons for fine tuning are a little bit, touch upon those use cases a little bit, but also are a bit more general. One of the limitations I've found with Doc Whisper is that I live in Israel, and I use some words in Hebrew that I just won't translate. The second one is I work in AI and development and tech, and a lot of vocabulary is technical, and that doesn't always translate well. But more than that, I guess the idea of fine tuning a model just on my unique voice and accent appeals to me, even if the accuracy of representation is modest. And I'm wondering if that more generalist driver or reason is sort of a legitimate reason for fine tuning an ASR