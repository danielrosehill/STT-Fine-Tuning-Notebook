I'd love to get a sense for what. When we talk about ASR fine-tuning, it's a complicated task, and it's a dedicated task that requires work in curating a data set and then training the model. Let's take an application where ASR speech text was being used in really mission-critical situations. Several that come to mind might be, and I've seen these mentioned, air traffic control, medical transcription. So in these cases, obviously the organization is going to go to great lengths to get the best. Let's assume that they've got an unlimited budget for this hypothetical situation, and they're going to get the absolute best ASR that they can and deploy to their team. What does an organization in this situation do? Is it even typical that people would go to the trouble of, you know, fine tuning or would they more turn towards maybe pre-existing specialist data sets? What might a typical implementation process look like at this kind of top level of where accuracy is paramount and non-negotiable? Where might your average organization turn to for the implementation and what kind of timeline would you be looking at between the various stages involved?